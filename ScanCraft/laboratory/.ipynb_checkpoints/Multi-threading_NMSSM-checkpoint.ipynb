{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,pandas,numpy,copy,shutil\n",
    "sys.path.append('/home/heyangle/Desktop/ScanCraft/ScanCraft')\n",
    "from command.scan import scan\n",
    "from command.NMSSMTools import NMSSMTools\n",
    "from command.NMSSMTools import ReadNMSSMToolsSpectr\n",
    "from command.operations.GetFiles import GetFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "free=scan()\n",
    "free.Add('tanB','MINPAR',3,1.,60.)\n",
    "free.Add('M1','EXTPAR',1  ,20.    ,1000.)\n",
    "free.Add('M2'\t,'EXTPAR'   ,2  ,100.    ,2000.)\n",
    "free.Add('Atop'\t,'EXTPAR'   ,11  ,  -6e3    ,6e3)\n",
    "free.Add('Abottom','EXTPAR'   ,12,-6e3,6e3,pace='follow Atop')\n",
    "free.Add('Atau'\t,'EXTPAR'   ,13  ,  100.      ,2000.)\n",
    "free.Add('MtauL','EXTPAR'   ,33,\t100.,\t2.e3,pace='follow Atau')\n",
    "free.Add('MtauR','EXTPAR'   ,36,\t100.,\t2.e3,pace='follow Atau')\n",
    "free.Add('MQ3L'\t,'EXTPAR'   ,43,\t100.,\t2.e3)\n",
    "free.Add('MtopR'\t,'EXTPAR'   ,46,\t100.,\t2.e3)\n",
    "free.Add('MbottomR','EXTPAR'  ,49,\t100.,\t2.e3 ,pace='follow MtopR')\n",
    "free.Add('Lambda','EXTPAR'  ,61  ,1e-3    ,1. ,pace='lognormal')\n",
    "free.Add('Kappa','EXTPAR'   ,62 ,1.e-3    ,1. ,pace='lognormal')\n",
    "free.Add('A_Lambda','EXTPAR' ,63,-3.e3,3.e3)\n",
    "free.Add('A_kappa','EXTPAR' ,64,-3.e3,3.e3)\n",
    "free.Add('mu_eff','EXTPAR'  ,65,100.,1500.)\n",
    "\n",
    "ignore=[ 'Landau Pole'#27\n",
    "        ,'relic density'#30\n",
    "        ,'b->s gamma'#32\n",
    "        ,'B_s->mu+mu-'#35\n",
    "        ,'Muon magn'#37\n",
    "        ,'No Higgs in the'#46\n",
    "        ,'b -> c tau nu'#58 always keep alive\n",
    "        ]\n",
    "\n",
    "free.GetValue('./Pylon/carrier/inpZ3.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "ore_queue=queue.Queue(20)\n",
    "for vt in range(20):\n",
    "    new_ore=copy.deepcopy(free)\n",
    "    new_ore.variable_list['tanB'].value=float(vt)+1.5\n",
    "    ore_queue.put(new_ore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading,time\n",
    "def warp(number):\n",
    "    position='./Pylon/prob'+str(number)\n",
    "    try:\n",
    "        shutil.copytree('./Pylon/prob/',position)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    N=NMSSMTools(package_dir=position,data_dir='./Pylon/carrier',in_model='inpZ3.dat',clean=False)\n",
    "    return N\n",
    "\n",
    "ore_lock=threading.Lock()\n",
    "samples_lock=threading.Lock()\n",
    "samples=[]\n",
    "class MT_NTools(threading.Thread):\n",
    "    def __init__(self,ID,sequence,samples):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.ID=ID\n",
    "        self.N=warp(ID)\n",
    "        self.sequence=sequence\n",
    "        self.samples=samples\n",
    "    def run(self):\n",
    "        while not self.sequence.empty():\n",
    "            ore_lock.acquire()\n",
    "            ore=self.sequence.get()\n",
    "            sys.stdout.write(' '.join([\n",
    "                repr(i) for i in [self.ID,'runing',ore.variable_list['tanB'].value,'at',time.ctime()]\n",
    "                ])+'\\n')\n",
    "            ore_lock.release()\n",
    "            \n",
    "            sample=self.N.Run(ore)\n",
    "            \n",
    "            samples_lock.acquire()\n",
    "            self.samples.append(sample)\n",
    "            sys.stdout.write(' '.join([\n",
    "                repr(i) for i in [self.ID,'done',sample.MINPAR,'at',time.ctime(),len(self.samples)]\n",
    "                ])+'\\n')\n",
    "            samples_lock.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 'runing' 1.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "2 'runing' 3.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "1 'runing' 2.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "3 'runing' 4.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "1 'done' {3: 2.5} 'at' 'Fri Nov 17 21:17:14 2017' 1\n",
      "1 'runing' 5.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "0 'done' {3: 1.5} 'at' 'Fri Nov 17 21:17:14 2017' 2\n",
      "0 'runing' 6.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "3 'done' {3: 4.5} 'at' 'Fri Nov 17 21:17:14 2017' 3\n",
      "3 'runing' 7.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "3 'done' {3: 7.5} 'at' 'Fri Nov 17 21:17:14 2017' 4\n",
      "3 'runing' 8.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "1 'done' {3: 5.5} 'at' 'Fri Nov 17 21:17:14 2017' 5\n",
      "1 'runing' 9.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "0 'done' {3: 6.5} 'at' 'Fri Nov 17 21:17:14 2017' 6\n",
      "0 'runing' 10.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "1 'done' {3: 9.5} 'at' 'Fri Nov 17 21:17:14 2017' 7\n",
      "1 'runing' 11.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "3 'done' {3: 8.5} 'at' 'Fri Nov 17 21:17:14 2017' 8\n",
      "3 'runing' 12.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "0 'done' {3: 10.5} 'at' 'Fri Nov 17 21:17:14 2017' 9\n",
      "0 'runing' 13.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "1 'done' {3: 11.5} 'at' 'Fri Nov 17 21:17:14 2017' 10\n",
      "1 'runing' 14.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "3 'done' {3: 12.5} 'at' 'Fri Nov 17 21:17:14 2017' 11\n",
      "3 'runing' 15.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "0 'done' {3: 13.5} 'at' 'Fri Nov 17 21:17:14 2017' 12\n",
      "0 'runing' 16.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "1 'done' {3: 14.5} 'at' 'Fri Nov 17 21:17:14 2017' 13\n",
      "1 'runing' 17.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "0 'done' {3: 16.5} 'at' 'Fri Nov 17 21:17:14 2017' 14\n",
      "0 'runing' 18.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "3 'done' {3: 15.5} 'at' 'Fri Nov 17 21:17:14 2017' 15\n",
      "3 'runing' 19.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "1 'done' {3: 17.5} 'at' 'Fri Nov 17 21:17:14 2017' 16\n",
      "1 'runing' 20.5 'at' 'Fri Nov 17 21:17:14 2017'\n",
      "0 'done' {3: 18.5} 'at' 'Fri Nov 17 21:17:14 2017' 17\n",
      "1 'done' {3: 20.5} 'at' 'Fri Nov 17 21:17:14 2017' 18\n",
      "3 'done' {3: 19.5} 'at' 'Fri Nov 17 21:17:14 2017' 19\n",
      "2 'done' {3: 3.5} 'at' 'Fri Nov 17 21:17:16 2017' 20\n"
     ]
    }
   ],
   "source": [
    "NT=[]\n",
    "for i in range(4):\n",
    "    NT.append(MT_NTools(i,ore_queue,samples))\n",
    "len(NT)\n",
    "for N_i in NT:\n",
    "    N_i.start()\n",
    "for N_i in NT:\n",
    "    N_i.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "1 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "2 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "3 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "4 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "5 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "6 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "7 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "8 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "9 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "10 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "11 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "12 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "13 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "14 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "15 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "16 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "17 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "18 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'ERROR', 'constraints'])\n",
      "19 dict_keys(['DECAY', 'SPINFO', 'MODSEL', 'SMINPUTS', 'MINPAR', 'EXTPAR', 'MASS', 'LOWEN', 'HMIX', 'NMHMIX', 'NMAMIX', 'STOPMIX', 'SBOTMIX', 'STAUMIX', 'NMNMIX', 'UMIX', 'VMIX', 'REDCOUP', 'HIGGSBOUNDSINPUTHIGGSCOUPLINGSBOSONS', 'HIGGSBOUNDSINPUTHIGGSCOUPLINGSFERMIONS', 'GAUGE', 'YU', 'YD', 'YE', 'AU', 'TU', 'AD', 'TD', 'AE', 'TE', 'MSOFT', 'NMSSMRUN', 'MSQ2', 'MSU2', 'MSD2', 'MSL2', 'MSE2', 'USQMIX', 'DSQMIX', 'SELMIX', 'GUTGAUGE', 'GUTYU', 'GUTYD', 'GUTYE', 'GUTAU', 'GUTAD', 'GUTAE', 'GUTMSOFT', 'GUTNMSSMRUN', 'FINETUNING', 'LHCCROSSSECTIONS', 'LHCFIT', 'EFFECTIVE_COUPLINGS', 'DCINFO', 'RDINFO', 'ABUNDANCE', 'LSP', 'NDMCROSSSECT', 'ANNIHILATION', 'ERROR', 'constraints'])\n"
     ]
    }
   ],
   "source": [
    "for i,sample in enumerate(samples):\n",
    "    print(i,sample.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['NMSSMTools'], 2: ['5.2.0'], 3: [], 4: ['# M_H1^2<1']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0].SPINFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
